{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in /usr/local/python/3.12.1/lib/python3.12/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/codespace/.local/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.12.1/lib/python3.12/site-packages (from nltk) (4.67.1)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: regex, nltk\n",
      "Successfully installed nltk-3.9.1 regex-2024.11.6\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/codespace/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instalação das bibliotecas (execute apenas se não estiverem instaladas)\n",
    "# !pip install gensim matplotlib scikit-learn pandas numpy spacy plotly\n",
    "\n",
    "# Importações básicas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "from sklearn.manifold import TSNE\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download de recursos NLTK (se necessário)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto 1: Este filme é incrível, adorei a atuação do protagonista\n",
      "Texto 2: A direção de fotografia é espetacular e o roteiro é envolvente\n",
      "Texto 3: Péssimo filme, desperdicei meu tempo assistindo isso\n"
     ]
    }
   ],
   "source": [
    "textos = [\n",
    "    \"Este filme é incrível, adorei a atuação do protagonista\",\n",
    "    \"A direção de fotografia é espetacular e o roteiro é envolvente\",\n",
    "    \"Péssimo filme, desperdicei meu tempo assistindo isso\",\n",
    "    \"Os atores são talentosos mas o roteiro é fraco\",\n",
    "    \"Cinematografia belíssima, recomendo assistir no cinema\",\n",
    "    \"Não gostei da história, personagens mal desenvolvidos\",\n",
    "    \"A trilha sonora combina perfeitamente com as cenas\",\n",
    "    \"Filme entediante, previsível do início ao fim\",\n",
    "    \"Os efeitos especiais são impressionantes, tecnologia de ponta\",\n",
    "    \"História emocionante, chorei no final do filme\"\n",
    "]\n",
    "\n",
    "# Verificando os dados\n",
    "for i, texto in enumerate(textos[:3]):  # Mostrando apenas os 3 primeiros\n",
    "    print(f\"Texto {i+1}: {texto}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemplo de texto original:\n",
      "Este filme é incrível, adorei a atuação do protagonista\n",
      "\n",
      "Depois do pré-processamento:\n",
      "['filme', 'incrível', 'adorei', 'atuação', 'protagonista']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def preprocessar_texto(texto):\n",
    "    # Converter para minúsculas\n",
    "    texto = texto.lower()\n",
    "\n",
    "    # Remover caracteres especiais e números\n",
    "    texto = re.sub(r'[^a-záàâãéèêíïóôõöúçñ ]', '', texto)\n",
    "\n",
    "    # Tokenizar\n",
    "    tokens = word_tokenize(texto)\n",
    "\n",
    "    # Remover stopwords (opcional, dependendo da aplicação)\n",
    "    stop_words = set(stopwords.words('portuguese'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "# Aplicar pré-processamento a todos os textos\n",
    "textos_preprocessados = [preprocessar_texto(texto) for texto in textos]\n",
    "\n",
    "# Verificar resultado\n",
    "print(\"Exemplo de texto original:\")\n",
    "print(textos[0])\n",
    "print(\"\\nDepois do pré-processamento:\")\n",
    "print(textos_preprocessados[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo treinado com 44 palavras no vocabulário\n"
     ]
    }
   ],
   "source": [
    "# Definir parâmetros do modelo\n",
    "vector_size = 100    # Dimensionalidade dos vetores\n",
    "window = 5           # Tamanho da janela de contexto\n",
    "min_count = 1        # Frequência mínima das palavras\n",
    "workers = 4          # Número de threads para treinamento\n",
    "sg = 1               # Modelo Skip-gram (1) ou CBOW (0)\n",
    "\n",
    "# Treinar o modelo\n",
    "model = Word2Vec(\n",
    "    sentences=textos_preprocessados,\n",
    "    vector_size=vector_size,\n",
    "    window=window,\n",
    "    min_count=min_count,\n",
    "    workers=workers,\n",
    "    sg=sg\n",
    ")\n",
    "\n",
    "print(f\"Modelo treinado com {len(model.wv.key_to_index)} palavras no vocabulário\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algumas palavras do vocabulário:\n",
      "['filme', 'história', 'roteiro', 'desperdicei', 'belíssima', 'cinematografia', 'fraco', 'talentosos', 'atores', 'assistindo']\n",
      "\n",
      "Vetor da palavra 'filme' (primeiras 10 dimensões):\n",
      "[-0.00053898  0.00023755  0.00510847  0.00900957 -0.00930602 -0.00711791\n",
      "  0.00645901  0.00897323 -0.00500892 -0.00376375]\n",
      "Dimensionalidade do vetor: 100\n"
     ]
    }
   ],
   "source": [
    "# Listar algumas palavras do vocabulário\n",
    "palavras = list(model.wv.key_to_index.keys())\n",
    "print(\"Algumas palavras do vocabulário:\")\n",
    "print(palavras[:10])  # Primeiras 10 palavras\n",
    "\n",
    "# Verificar o vetor de uma palavra específica\n",
    "if 'filme' in model.wv:\n",
    "    vetor_filme = model.wv['filme']\n",
    "    print(f\"\\nVetor da palavra 'filme' (primeiras 10 dimensões):\")\n",
    "    print(vetor_filme[:10])\n",
    "    print(f\"Dimensionalidade do vetor: {len(vetor_filme)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Palavras mais similares a 'filme':\n",
      "direção: 0.2189\n",
      "assistindo: 0.2168\n",
      "impressionantes: 0.1955\n",
      "cinema: 0.1694\n",
      "efeitos: 0.1520\n"
     ]
    }
   ],
   "source": [
    "# Encontrar palavras mais similares a 'filme'\n",
    "if 'filme' in model.wv:\n",
    "    similares = model.wv.most_similar('filme', topn=5)\n",
    "    print(\"\\nPalavras mais similares a 'filme':\")\n",
    "    for palavra, similaridade in similares:\n",
    "        print(f\"{palavra}: {similaridade:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
